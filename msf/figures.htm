<!--This file created 10:03 AM  7/27/97 by Claris Home Page version 2.0-->
<HTML>
<HEAD>
   <TITLE>Figures</TITLE>
   <META NAME=GENERATOR CONTENT="Claris Home Page 2.0">
   <X-SAS-WINDOW TOP=52 BOTTOM=463 LEFT=8 RIGHT=763>
</HEAD>
<BODY BGCOLOR="#FFFFFF">

<H2>List of Tables</H2>

<P>TABLE 1:  COMPARISON OF FUSION LEVELS (ADAPTED FROM [53])	</P>

<P>TABLE 2: CONFLICTS BETWEEN SENSING TASKS AND CAMERA MOTION	</P>

<P>TABLE 3: ROOM EXPERIMENT DATA	</P>

<P>&nbsp;</P>

<H2>List of Figures</H2>

<P>FIGURE 1: AUDIO-VISUAL SENSOR FUSION IN THE BARN OWL	</P>

<P>FIGURE 2: SENSOR CONFIGURATION	</P>

<P>FIGURE 3:  COMPONENT INTERCONNECTIONS	</P>

<P>FIGURE 4: DATA FLOW BLOCK DIAGRAM	</P>

<P>FIGURE 5: SOUND LOCALIZATION GEOMETRY	</P>

<P>FIGURE 6: ONSET SIGNAL GENERATION	</P>

<P>FIGURE 7: DIRECT AND ECHO PATH LENGTHS	</P>

<P>FIGURE 8: ECHO/DIRECT SOUND VOLUME RATIO DECAY RATES	</P>

<P>FIGURE 9: STEREO SAMPLING OF THE WORD "TESTING"	</P>

<P>FIGURE 10: ENVELOPE SIGNALS FROM "TESTING"	</P>

<P>FIGURE 11: ONSET SIGNALS FROM "TESTING"	</P>

<P>FIGURE 12: CROSS-CORRELATION  OF ONSET SIGNALS AND ORIGINAL
SIGNALS	</P>

<P>FIGURE 13: GAIN OF THE ONSET GENERATION PROCESS	</P>

<P>FIGURE 14: ROOM LAYOUT WITH SPEAKER AND MICROPHONE LOCATIONS	
</P>

<P>FIGURE 15: MIRRORED-ROOM METHOD OF  ECHO IMAGING	</P>

<P>FIGURE 16: FIR CONVOLUTION OPERATOR FOR LEFT MICROPHONE, SPEAKER
LOCATION 20, 50% WALL ABSORPTION	</P>

<P>FIGURE 17: ONSET CORRELATION FOR TIME-DOMAIN ECHO SIMULATION,
LOCATIONS 5(8, 50% ABSORPTION	</P>

<P>FIGURE 18: RAW CROSS-CORRELATION FOR SPEAKER LOCATIONS 1(8, 50%
ABSORPTION	</P>

<P>FIGURE 19: SOUND ABSORPTION OF CARPET (SOLID) AND CEILING TILE
(DOTTED)	</P>

<P>FIGURE 20: ONSET CORRELATION FOR FREQUENCY-DOMAIN SIMULATION,
LOCATIONS 17(20	</P>

<P>FIGURE 21: RAW CORRELATION FOR FREQUENCY DOMAIN SIMULATION,
LOCATIONS 17(20	</P>

<P>FIGURE 22: ONSET CORRELATION FOR ROOM EXPERIMENT, LOCATIONS 5(8	
</P>

<P>FIGURE 23: RAW CORRELATION FOR ROOM EXPERIMENT, LOCATIONS 5(8	
</P>

<P>FIGURE 24: LOCALIZATION ERRORS FOR ONSET AND RAW CORRELATION	
</P>

<P>FIGURE 25: PERFORMANCE FOR TWO SPEAKERS	</P>

<P>FIGURE 26: ORIGINAL IMAGE	</P>

<P>FIGURE 27: CURRENT IMAGE	</P>

<P>FIGURE 28: PIXELS CHANGED	</P>

<P>FIGURE 29: ORIGINAL IMAGE	</P>

<P>FIGURE 30: INTER-FRAME DIFFERENCE	</P>

<P>FIGURE 31: DETECTED HUMAN	</P>

<P>FIGURE 32: ORIGINAL CAMERA IMAGE	</P>

<P>FIGURE 33: ORIGINAL REFERENCE IMAGE	</P>

<P>FIGURE 34: OBJECT BEING ASSIMILATED INTO IMAGE	</P>

<P>FIGURE 35: FINAL REFERENCE IMAGE	</P>

<P>FIGURE 36: SPHERE UNDER ILLUMINATION	</P>

<P>FIGURE 37: SPECTRAL CLUSTERING	</P>

<P>FIGURE 38: CHROMATICITY SPACE	</P>

<P>FIGURE 39: SKIN TONE CHROMATICITY SAMPLE POPULATION	</P>

<P>FIGURE 40: IMAGE OF THE AUTHOR	</P>

<P>FIGURE 41: DETECTION OF SKIN PIXELS	</P>

<P>FIGURE 42: DETECTION OF FACES BY CHOOSING THE LARGEST SKIN
TONE-COLORED REGION	</P>

<P>FIGURE 43: PIXEL-LEVEL AUDIOVISUAL FUSION FOR DETECTING A TALKING
FACE	</P>

<P>FIGURE 44: IMAGES FROM SOUND LOCALIZATION DATA	</P>

<P>FIGURE 45: AUDIOVISUAL FUSION GEOMETRY	</P>

<P>FIGURE 46: FUSION OF SOUND LOCALIZATION WITH SKIN TONE	</P>

<P>FIGURE 47: TARGET DETECTION AFTER FILTERING AND SEGMENTATION.	
</P>

<P>FIGURE 48: COLOR IMAGE	</P>

<P>FIGURE 49: DETECTION OF PERSON SPEAKING	</P>

<P>FIGURE 50: TRACKING IN THREE DIMENSIONS	</P>

<P>FIGURE 51: MODEL OF TARGET DYNAMICS	</P>

<P>FIGURE 52: NOISE ENTERING THE PLANT	</P>

<P>FIGURE 53: TRACKING A PERSON WALKING	</P>

<P>FIGURE 54: POSITION ESTIMATE WHILE TRACKING A FACE	</P>

<P>FIGURE 55: TARGET TRACKING OF A FACE IN 3D	</P>

<P>FIGURE 56: EXAMPLE MEMBERSHIP FUNCTIONS	</P>

<P>FIGURE 57: CENTROID FOR FUZZY OUTPUT	</P>

<P>FIGURE 58: CENTROID FOR SINGLETON OUTPUT	</P>

<P>FIGURE 59: RULE COMPONENTS	</P>

<P>FIGURE 60: COMBINATION OF RULES	</P>

<P>FIGURE 61: ACCEPTABLE COMPROMISES	</P>

<P>FIGURE 62: MUTUALLY EXCLUSIVE OPTIONS	</P>

<P>FIGURE 63: UNACCEPTABLE CENTROIDS	</P>

<P>FIGURE 64: FUSION OF LOCAL AGENTS BY A FUZZY MULTIPLEXER	</P>

<P>FIGURE 65: SOUND-FOLLOWING BEHAVIOR	</P>

<P>FIGURE 66:  CAMERA MOTION FOLLOWING SOUND	</P>

<P>FIGURE 67:  BEHAVIOR FOR FOLLOWING A FACE	</P>

<P>FIGURE 68: INTEGRATION OF FACE AND SOUND TRACKING	</P>

<P>FIGURE 69:  FACE SELECTION AND CAMERA RESPONSE DUE TO SOUND
DIRECTION	</P>

<P>FIGURE 70: CAMERA BEHAVIOR WHILE FOLLOWING A CONVERSATION	</P>

<P>FIGURE 71: CAMERA PAN BEHAVIOR WHEN TRACKING A FACE	</P>

<P>FIGURE 72: FOLLOW-MOVING-TARGET BEHAVIOR COMPONENTS	</P>

<P>FIGURE 73: CAMERA PAN BEHAVIOR WHEN TRACKING A BODY	</P>

<P>FIGURE 74: BEHAVIOR COMPONENTS FOR VIDEOCONFERENCING	</P>

<P>FIGURE 75:  GEOMETRY OF FACE WIDTH ANGLE	</P>

<P>FIGURE 76: CAMERA BEHAVIOR FOR VIDEOCONFERENCING	</P>

<P>FIGURE 77: BEHAVIOR INTEGRATION FOR SURVEILLANCE	</P>

<P>FIGURE 78: CAMERA TRACKING MOTION FOR SURVEILLANCE	</P>

<P>&nbsp;</P>

<P>&nbsp;</P>

<P>&nbsp;</P>
</BODY>
</HTML>
